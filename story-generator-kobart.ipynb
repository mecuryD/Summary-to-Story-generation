{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2962fbf6",
   "metadata": {},
   "source": [
    "#### 토크나이저 및 모델 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "468fad67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\torch-py38\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration, AutoModel\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") # gpu\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gogamza/kobart-base-v2\") # tokenizer\n",
    "model = BartForConditionalGeneration.from_pretrained(\"gogamza/kobart-base-v2\").to(device) # model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b11ca0",
   "metadata": {},
   "source": [
    "#### 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f0c0634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import datasets\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af180e98",
   "metadata": {},
   "source": [
    "**Train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4bdaf5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_texts</th>\n",
       "      <th>target_texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>아내에게 돈이 있을지 모른다는 귀띔을 문 서방은 믿을 수 없었으나 아내에게는 역시 ...</td>\n",
       "      <td>그러나 그보다도 절통한 것은 아내의 어리석음에서 생긴 비극이었다. 문 서방이 한이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>남 주사와 일지매는 승강기 맨 앞에 서서 윗층으로 올라가게 되었으나 해룡피 외투는 ...</td>\n",
       "      <td>일지매는 그 신사의 뒷모양이 선듯 눈에 띄자 공연히 가슴이 울렁하며 한 치각이나 아...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>화증이 나는 것을 참고 삯군을 서넛이구 사보라 했더니 들은 성도 않고 걸레질만 치다...</td>\n",
       "      <td>“삯군을 서넛이구 좀 사보게?” 화증이 나는 것을 짐짓 참고, 순순히 말로 일렀다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>농익은 연시와 같이 붉은 뺨의 처녀들이 웃고 지껄이며 지나간다.</td>\n",
       "      <td>어느새 임해전 길고 넓은 복도와 뜰엔 사람의 사태다. 활짝 열어 제친 궁문 으로 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>미란이가 동경 여행 이야기를 할 때 울적한 표정으로 조용히 앉아있던 단주에게 왜 말...</td>\n",
       "      <td>단주는 주인이 돌아온 이상 자기의 직책은 다한 듯 다음날부터 제대로 아 파트로 돌...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         input_texts  \\\n",
       "0  아내에게 돈이 있을지 모른다는 귀띔을 문 서방은 믿을 수 없었으나 아내에게는 역시 ...   \n",
       "1  남 주사와 일지매는 승강기 맨 앞에 서서 윗층으로 올라가게 되었으나 해룡피 외투는 ...   \n",
       "2  화증이 나는 것을 참고 삯군을 서넛이구 사보라 했더니 들은 성도 않고 걸레질만 치다...   \n",
       "3                농익은 연시와 같이 붉은 뺨의 처녀들이 웃고 지껄이며 지나간다.   \n",
       "4  미란이가 동경 여행 이야기를 할 때 울적한 표정으로 조용히 앉아있던 단주에게 왜 말...   \n",
       "\n",
       "                                        target_texts  \n",
       "0   그러나 그보다도 절통한 것은 아내의 어리석음에서 생긴 비극이었다. 문 서방이 한이...  \n",
       "1  일지매는 그 신사의 뒷모양이 선듯 눈에 띄자 공연히 가슴이 울렁하며 한 치각이나 아...  \n",
       "2   “삯군을 서넛이구 좀 사보게?” 화증이 나는 것을 짐짓 참고, 순순히 말로 일렀다...  \n",
       "3   어느새 임해전 길고 넓은 복도와 뜰엔 사람의 사태다. 활짝 열어 제친 궁문 으로 ...  \n",
       "4   단주는 주인이 돌아온 이상 자기의 직책은 다한 듯 다음날부터 제대로 아 파트로 돌...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries = []\n",
    "passages = []\n",
    "\n",
    "# 두 개의 폴더에 나눠져 있는 데이터를 리스트에 모은다\n",
    "## 2~3sent\n",
    "for f_name in glob(os.path.join(\"D:/jupyter/story-generation/data/story/summarization/train\",\"literature/2~3sent/*.json\")) :\n",
    "    with open(f_name, 'r',encoding=\"utf-8\") as f:\n",
    "        json_data = json.load(f)\n",
    "        passages.append(json_data['Meta(Refine)']['passage'])\n",
    "        summaries.append(json_data['Annotation']['summary1'])\n",
    "        \n",
    "## 20per\n",
    "for f_name in glob(os.path.join(\"D:/jupyter/story-generation/data/story/summarization/train\" ,\"literature/20per/*.json\")) :\n",
    "    with open(f_name, 'r',encoding=\"utf-8\") as f:\n",
    "        json_data = json.load(f)\n",
    "        passages.append(json_data['Meta(Refine)']['passage'])\n",
    "        summaries.append(json_data['Annotation']['summary1'])\n",
    "\n",
    "# 한자 제거\n",
    "passages = [re.sub(\"\\([^\\(\\)]+\\)\", \"\", passage) for passage in passages]\n",
    "\n",
    "train_df = pd.DataFrame([ x for x in zip(summaries, passages)], columns = [\"input_texts\",\"target_texts\"])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3ca0e7",
   "metadata": {},
   "source": [
    "**Valid Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c950ed20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_texts</th>\n",
       "      <th>target_texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>동경으로 떠나게 된 실은 눈을 붉히며 떠날 용기가 나지 않아서 떠나는 날짜를 흐려오...</td>\n",
       "      <td>“이 걱정쟁이 같으니 누굴 칠면조나 카멜레온으로 아나부다.” “저 없는 동안에 모...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>입내할 채비를 갖추고 기다리고 있던 대원군은 날이 어둔 후 창덕궁으로 들어갔다.</td>\n",
       "      <td>그에 대조되어, 세도하고 행학하던 사람들은 벼락을 맞은 듯 숨어 들어가 몸을 떨었...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>어머니께 가면 항상 친절하게 잘해주셨지만 아파트의 사무원은 그만두라는 말을 항상 하...</td>\n",
       "      <td>“면도를 빌려드릴까요?” 그러니까 사내는 머리를 극적극적 긁으며, “에이 뭐 면도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>어둠 속에서도 자태는 또렷했고 충동적으로 몸은 쏠리었는데 그 순간 눈을 굴린 것은 ...</td>\n",
       "      <td>야릇한 방, 페페의 정성, 준비된 식탁, 갸비이의 호기심, 페페의 열정 ─ 두 사람...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>흥식이는 옥지의 말을 너무도 신용하는 우식이가 미워서 혼사 준비에 대해 말을 하지 ...</td>\n",
       "      <td>과연 틀림이 없다. 백작의 집에서는 혼사 준비에 골몰하는 것을 볼진대 옥 지의 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         input_texts  \\\n",
       "0  동경으로 떠나게 된 실은 눈을 붉히며 떠날 용기가 나지 않아서 떠나는 날짜를 흐려오...   \n",
       "1       입내할 채비를 갖추고 기다리고 있던 대원군은 날이 어둔 후 창덕궁으로 들어갔다.   \n",
       "2  어머니께 가면 항상 친절하게 잘해주셨지만 아파트의 사무원은 그만두라는 말을 항상 하...   \n",
       "3  어둠 속에서도 자태는 또렷했고 충동적으로 몸은 쏠리었는데 그 순간 눈을 굴린 것은 ...   \n",
       "4  흥식이는 옥지의 말을 너무도 신용하는 우식이가 미워서 혼사 준비에 대해 말을 하지 ...   \n",
       "\n",
       "                                        target_texts  \n",
       "0   “이 걱정쟁이 같으니 누굴 칠면조나 카멜레온으로 아나부다.” “저 없는 동안에 모...  \n",
       "1   그에 대조되어, 세도하고 행학하던 사람들은 벼락을 맞은 듯 숨어 들어가 몸을 떨었...  \n",
       "2   “면도를 빌려드릴까요?” 그러니까 사내는 머리를 극적극적 긁으며, “에이 뭐 면도...  \n",
       "3  야릇한 방, 페페의 정성, 준비된 식탁, 갸비이의 호기심, 페페의 열정 ─ 두 사람...  \n",
       "4   과연 틀림이 없다. 백작의 집에서는 혼사 준비에 골몰하는 것을 볼진대 옥 지의 2...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries = []\n",
    "passages = []\n",
    "\n",
    "# 두 개의 폴더에 나눠져 있는 데이터를 리스트에 모은다\n",
    "## 2~3sent\n",
    "for f_name in glob(os.path.join(\"D:/jupyter/story-generation/data/story/summarization/valid\",\"literature/2~3sent/*.json\")) :\n",
    "    with open(f_name, 'r',encoding=\"utf-8\") as f:\n",
    "        json_data = json.load(f)\n",
    "        passages.append(json_data['Meta(Refine)']['passage'])\n",
    "        summaries.append(json_data['Annotation']['summary1'])\n",
    "        \n",
    "## 20per\n",
    "for f_name in glob(os.path.join(\"D:/jupyter/story-generation/data/story/summarization/valid\" ,\"literature/20per/*.json\")) :\n",
    "    with open(f_name, 'r',encoding=\"utf-8\") as f:\n",
    "        json_data = json.load(f)\n",
    "        passages.append(json_data['Meta(Refine)']['passage'])\n",
    "        summaries.append(json_data['Annotation']['summary1'])\n",
    "\n",
    "# 한자 제거\n",
    "passages = [re.sub(\"\\([^\\(\\)]+\\)\", \"\", passage) for passage in passages]\n",
    "\n",
    "valid_df = pd.DataFrame([ x for x in zip(summaries, passages)], columns = [\"input_texts\",\"target_texts\"])\n",
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1392a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train_data.csv\", index=False)\n",
    "valid_df.to_csv(\"valid_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0deb3d99",
   "metadata": {},
   "source": [
    "**Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4842693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "valid_dataset = Dataset.from_pandas(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4bdf88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train ]\n",
      "\n",
      "input :  자기의 잘못으로 박 흥식에게 위협을 당한 김 정자는 분해서 가슴이 터질 지경이다.\n",
      "target :   박 흥식에게 위협을 당한 김 정자는 분한 마음이 폭발하여 가슴이 터질 지 경이다. 그러나, 도무지 자기의 잘못인즉 누구를 원망하리요. 허영에 침혹 된 여자란 이같은 일이 한두 번이 아닐 것이다. 전번에는 별별 비루한 행동을 다하고 할 소리 못 할 소리를 다하면서 사 랑하느니 무엇하느니 하던 김 정자도 일시 허영으로 인하여 김 자작집으로 시집을 가버렸다. 이같은 창피한 경우를 당한 박 흥식의 분풀이도 사실로 말하면 당연한 일이라고 할 수 밖에 없다. 그러나, 김 정자는 무슨 염치와 무슨 면목으로 그같이 뻔뻔한지 도무지 흥 식의 하는 말을 듣지 않으려고만 한다. 그러다가 필경 흥식의 최후 수단으 로 그 편지를 자기 남편되는 김 자작에게 보이겠다는 말에는 정자 부인도 놀라지 않을 수 없었다. 그 까닭에 자기의 가장 사랑하던 진주목걸이까지 내어놓으려고 했다. 그러나, 흥식이는 오히려 만족히 알지 못하는 모양이다. 그리하여 두 사람 사이에는 또 다시 정론이 일어났다. 흥식은, 정자 씨, 그 손에 낀 반지도 내어놓으시오. 아마 그것은 값 나갈 듯하 니…… 다른 것은 다 내어놓아도 이것은 못 내놓겠읍니다. 왜 그래요? 그러면 어떻게 하신다는 말씀이오? 그것은 결혼 반지입니다. 남작이 손수 끼워 준 것이니까 여자가 되어 결 혼 반지를 빼앗기면 이혼한 것이나 다를 것이 무엇입니까? 흥! 말은 좋소. 결혼 반지? 내게서도 이전에 그같은 반지를 받았지요? 그리고 또 이것은 누구에게서 받은 반지란 말이오? 이 말에는 정자 부인으로도 아무 대답이 없었다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('[ Train ]\\n')\n",
    "print('input : ', train_dataset['input_texts'][300])\n",
    "print('target : ', train_dataset['target_texts'][300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dc5617d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Validation ]\n",
      "\n",
      "input :  꿈은 젊은이의 양식이라지만 놀음을 갔다가도 그 꿈이 떠오르면 모든 게 시들해지고 그야말로 기적이었다.\n",
      "target :   ─ 그것은 짤막한 놀음이었어요. 두 시간도 채 못됐던가 해요. 아마 작정 이 두 시간이었던 모양인데 지금 생각하니 시간이 지날까봐 그것을 겁냈던 것 같아요. 그러기에 제 시간도 다 채우지 못하고 주춤주춤 일어났던 게 죠… 아마 그것이 기생생활 오륙 년 동안에 가장 인상깊었던 놀음인가 해요. 무엇이라고 설명키는 어려워도 가슴속에 무슨 뭉클한 감정이 며칠을 두고 남겠지요. 그중에서도 그 이야기를 하던 젊은이의 인상이 얼마를 두고 머리에서 사라 지지 않습디다. 그날 밤 그 자리가 아마 내게는 기적이었던가 해요. 바로 그날 밤이었어 요. 나는 그 사람의 꿈을 꾸었어요. 그 우렁차고 부드러운 말소리로 내 귀 에다 대고, “취향이, 이런 생활이 그렇게도 좋단 말이오. 달리 방도를 차리시오. 기 생생활에 견딜 만한 노력을 아끼지 않는다면 굶어 죽기야 하겠소?” 나는 이렇게 대답하였더라오. “내게는 그런 기적이 없었답니다.” “기적? 그러나 기적을 기다리는 것은 너무 소극적이오… 기적을 기다려서 는 안되오. 자진해서 그 기적을 만드시오!” 아우님! 꿈이란 할 수 없더군요. 바로 요 며칠 전에 잡지에선가 “꿈은 젊 은이의 양식”이란 말이 있습디다만 꿈이란 젊은이에게 있어선 안될 것이 라고 난 생각해요! 뭐야요? 글쎄, 그 꿈이란 말이 이상이라는 의미라면 모 르겠지마는… 어쨌든 그 꿈은 얼마를 두고 나를 울렸어요! 놀음을 갔다가도 문득 그 꿈 생각이 나면 그대로 모든 게 다 시들해지구… 그것이야말로 기적이었어요. 적어도 내게 있어선 더없이 기묘한 기적이었 던 것을… 박복한 취향이는 그 기적을 꼭 잡지 못했군요.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('[ Validation ]\\n')\n",
    "print('input : ', valid_dataset['input_texts'][300])\n",
    "print('target : ', valid_dataset['target_texts'][300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb6e431",
   "metadata": {},
   "source": [
    "**Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b18d40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [doc for doc in examples[\"input_texts\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True,padding='max_length')\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"target_texts\"], max_length=max_target_length, truncation=True,padding='max_length')\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d6c13a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 문장과 타켓 문장 토큰의 최대 토큰 길이 지정\n",
    "max_input_length = 64\n",
    "max_target_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fca64260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function preprocess_function at 0x00000211AAEAD8B8> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.11ba/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  6.96ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 9600\n",
      "})\n",
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 1200\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#train_data =train_dataset.map(preprocess_function, batched=True)\n",
    "#eval_data =eval_dataset.map(preprocess_function, batched=True)\n",
    "#train_data = train_data[['input_ids','attention_mask','label']]\n",
    "\n",
    "train_data =train_dataset.map(preprocess_function, batched=True).remove_columns([\"input_texts\",\"target_texts\",\"token_type_ids\"])\n",
    "valid_data =valid_dataset.map(preprocess_function, batched=True).remove_columns([\"input_texts\",\"target_texts\",\"token_type_ids\"])\n",
    "\n",
    "\n",
    "print(train_data)\n",
    "print(valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712598ef",
   "metadata": {},
   "source": [
    "#### 모델 훈련 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244526b4",
   "metadata": {},
   "source": [
    "**Arguments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31e6dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, Trainer\n",
    "from transformers import DataCollatorForSeq2Seq, get_cosine_schedule_with_warmup\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\".results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=2,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "#    fp16=True,\n",
    "    predict_with_generate=True,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a34ffcd",
   "metadata": {},
   "source": [
    "**Metric (평가 함수)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6ba9cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "metric = load_metric(\"rouge\")\n",
    "\n",
    "\n",
    "# 문장을 줄바꿈으로 구분하는 함수\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "# Trainer에 전달할 평가 함수\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "        \n",
    "    # 디코딩\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True) # 생성 결과 텍스트 디코딩\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id) # 레이블 내 -100 교체\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True) # 레이블 텍스트 디코딩\n",
    "\n",
    "    # 각 문장을 개행문자로 구분 (ROUGE는 각 문장 다음에 개행문자를 요구한다.)\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "    \n",
    "    # ROUGE 점수 계산\n",
    "    result = metric.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    # 중간 점수 (median) 추출\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49163129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset = train_data,\n",
    "    eval_dataset = valid_data,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f660cca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\torch-py38\\lib\\site-packages\\transformers\\optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 9600\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4800\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4800' max='4800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4800/4800 23:35, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.403600</td>\n",
       "      <td>3.292727</td>\n",
       "      <td>0.926100</td>\n",
       "      <td>0.241700</td>\n",
       "      <td>0.911500</td>\n",
       "      <td>0.907700</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.289800</td>\n",
       "      <td>3.261404</td>\n",
       "      <td>0.852600</td>\n",
       "      <td>0.247200</td>\n",
       "      <td>0.845200</td>\n",
       "      <td>0.851700</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to .results\\checkpoint-500\n",
      "Configuration saved in .results\\checkpoint-500\\config.json\n",
      "Model weights saved in .results\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in .results\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in .results\\checkpoint-500\\special_tokens_map.json\n",
      "Deleting older checkpoint [.results\\checkpoint-23000] due to args.save_total_limit\n",
      "Saving model checkpoint to .results\\checkpoint-1000\n",
      "Configuration saved in .results\\checkpoint-1000\\config.json\n",
      "Model weights saved in .results\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in .results\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in .results\\checkpoint-1000\\special_tokens_map.json\n",
      "Deleting older checkpoint [.results\\checkpoint-23500] due to args.save_total_limit\n",
      "Saving model checkpoint to .results\\checkpoint-1500\n",
      "Configuration saved in .results\\checkpoint-1500\\config.json\n",
      "Model weights saved in .results\\checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in .results\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in .results\\checkpoint-1500\\special_tokens_map.json\n",
      "Deleting older checkpoint [.results\\checkpoint-24000] due to args.save_total_limit\n",
      "Saving model checkpoint to .results\\checkpoint-2000\n",
      "Configuration saved in .results\\checkpoint-2000\\config.json\n",
      "Model weights saved in .results\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in .results\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in .results\\checkpoint-2000\\special_tokens_map.json\n",
      "Deleting older checkpoint [.results\\checkpoint-500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1200\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to .results\\checkpoint-2500\n",
      "Configuration saved in .results\\checkpoint-2500\\config.json\n",
      "Model weights saved in .results\\checkpoint-2500\\pytorch_model.bin\n",
      "tokenizer config file saved in .results\\checkpoint-2500\\tokenizer_config.json\n",
      "Special tokens file saved in .results\\checkpoint-2500\\special_tokens_map.json\n",
      "Deleting older checkpoint [.results\\checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to .results\\checkpoint-3000\n",
      "Configuration saved in .results\\checkpoint-3000\\config.json\n",
      "Model weights saved in .results\\checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in .results\\checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in .results\\checkpoint-3000\\special_tokens_map.json\n",
      "Deleting older checkpoint [.results\\checkpoint-1500] due to args.save_total_limit\n",
      "Saving model checkpoint to .results\\checkpoint-3500\n",
      "Configuration saved in .results\\checkpoint-3500\\config.json\n",
      "Model weights saved in .results\\checkpoint-3500\\pytorch_model.bin\n",
      "tokenizer config file saved in .results\\checkpoint-3500\\tokenizer_config.json\n",
      "Special tokens file saved in .results\\checkpoint-3500\\special_tokens_map.json\n",
      "Deleting older checkpoint [.results\\checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to .results\\checkpoint-4000\n",
      "Configuration saved in .results\\checkpoint-4000\\config.json\n",
      "Model weights saved in .results\\checkpoint-4000\\pytorch_model.bin\n",
      "tokenizer config file saved in .results\\checkpoint-4000\\tokenizer_config.json\n",
      "Special tokens file saved in .results\\checkpoint-4000\\special_tokens_map.json\n",
      "Deleting older checkpoint [.results\\checkpoint-2500] due to args.save_total_limit\n",
      "Saving model checkpoint to .results\\checkpoint-4500\n",
      "Configuration saved in .results\\checkpoint-4500\\config.json\n",
      "Model weights saved in .results\\checkpoint-4500\\pytorch_model.bin\n",
      "tokenizer config file saved in .results\\checkpoint-4500\\tokenizer_config.json\n",
      "Special tokens file saved in .results\\checkpoint-4500\\special_tokens_map.json\n",
      "Deleting older checkpoint [.results\\checkpoint-3000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1200\n",
      "  Batch size = 4\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4800, training_loss=3.4262604904174805, metrics={'train_runtime': 1418.0734, 'train_samples_per_second': 13.539, 'train_steps_per_second': 3.385, 'total_flos': 731683749888000.0, 'train_loss': 3.4262604904174805, 'epoch': 2.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef0c1673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1200\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 01:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.2614035606384277,\n",
       " 'eval_rouge1': 0.8526,\n",
       " 'eval_rouge2': 0.2472,\n",
       " 'eval_rougeL': 0.8452,\n",
       " 'eval_rougeLsum': 0.8517,\n",
       " 'eval_gen_len': 20.0,\n",
       " 'eval_runtime': 66.2722,\n",
       " 'eval_samples_per_second': 18.107,\n",
       " 'eval_steps_per_second': 4.527,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466cf74c",
   "metadata": {},
   "source": [
    "#### 인퍼런스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860293e9",
   "metadata": {},
   "source": [
    "**체크포인트 로드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470f91db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load ckpt\n",
    "\n",
    "ForConditionalGeneration.from_pretrained(\".results/checkpoint-12000\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309e2477",
   "metadata": {},
   "source": [
    "**인퍼런스 함수**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d9c3f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  7.22ba/s]\n"
     ]
    }
   ],
   "source": [
    "def generate_output(test_samples, model):\n",
    "    inputs = tokenizer(\n",
    "        test_samples[\"input_texts\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_target_length,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    input_ids = inputs.input_ids.to(model.device)\n",
    "    attention_mask = inputs.attention_mask.to(model.device)\n",
    "    outputs = model.generate(input_ids,\n",
    "                             max_length = 256,\n",
    "                             min_length=32,\n",
    "                             top_p = 0.92,\n",
    "                             num_beams=5,\n",
    "                             no_repeat_ngram_size=2,\n",
    "                             attention_mask=attention_mask)\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return outputs, output_str\n",
    "\n",
    "\n",
    "valid_data_t = valid_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "test_samples = valid_data_t.select(range(10))\n",
    "\n",
    "#model_before_tuning = BartForConditionalGeneration.from_pretrained(\"gogamza/kobart-base-v2\")\n",
    "\n",
    "\n",
    "#summaries_before_tuning = generate_output(test_samples, model_before_tuning)[1]\n",
    "summaries_after_tuning = generate_output(test_samples, model)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bd489d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Id  Output (Fine-tuned)\n",
      "----  ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "   0  동경으로 떠나게 된 실은 눈을 붉히며 떠날 용기가 나지 않아서 떠나는 날짜를 흐려오던 것이다. “여보게, 이놈아.” 하고 그는 눈을 번쩍 떴다. “왜?” “글쎄요!” “그래서요?” “아니오, 그까짓 게 무슨 소용이 있단 말요.” 실의 눈에는 눈물이 핑 돌았다. “네, 알겠어요.” “이놈아, 이 놈아!......” 실은 눈을 찡그리며 이렇게 대답하였다. “.........” “어디로 갈까?” 그는 다시 한 번 눈을 흘기며 물었다. “동경.........................그런데......?......이 놈아, 그놈의 놈이!...... 그 놈, 저 놈의 녀석아...... 이 년아, 저놈! 이년아, 네놈, 네 놈! 저 년, 너 같은 놈을...... 저년, 내 년...... 네 년! 네년! 내년 봄에...... 그래, 자네 같은 년이 어디 있겠니? 응? 네년이 어디 있어? 그 년의 년이란 년은 네게 무슨 죄가 있나? 내년이 누구냐? 네년의 년이야? 자네가 그년 년 년을 어떻게 지내왔단 말이냐?\n",
      "   1  대원군은 날이 어둔 후 창덕궁으로 들어갔다. 입내할 채비를 갖추어 놓고 기다리고 있던 대원군이었다. 날이 벌써 어둑한 후였다. 날이 밝아오자 대궐로 들어가서 입궐할 준비를 하고 있는 대원군을 기다리던 중이었다. 대원군이 입궁을 하려 할 때에, 대원군의 눈에는 눈물이 그렁그렁하였다. “여보게, 이놈아!” “응?” “대장군.” 대장은 눈을 번쩍 떴다. 대장의 눈에서는 눈물이 글썽글썽하였다. 대군은 눈을 감았다. 대장이 눈을 뜨고 대장을 바라보다가 대문을 나서서 대문 밖으로 나왔다. “대장, 이 놈아, 이 년아, 저 년아. 이년아, 이리 오너라.” 대원군과 대장도 눈을 부릅뜨며 대장에게 이렇게 말하였 다. 대장과 대사는 대청마루에 올라서서 머리를 숙이고 대사를 기다렸다. 대사와 대령은 대청을 향하여 “저놈, 저놈이......” 하고 대꾸를 하였다.\n",
      "      대장은 대문이 열리기를 기다렸으나 대문은 열리지 않았다. 대사의 눈은 대문으로 향하고 있었다. 대왕은 대좌의 자리에 앉으셨다. \"대장군, 어서 이리로 오십시오.\"\n",
      "   2  어머니께 가면 항상 친절하게 잘해주셨다. 아파트의 사무원은 그만두라는 말을 항상 하셨다. 오늘은 동경 같은 곳으로 학교를 다녀보는 게 어떻겠느냐는 말까지 나왔다. “여보게, 학교는 왜 다니나?” “네, 학교에 다니지요.” “그러면 어때요?” “어디를 가나.” “아무 데나.......” “이리 오너라.” 어머니는 이렇게 말씀하셨다. “그래, 어째서 학교를 못 다니게 되었니?’ “학교를 못다니게 된 것이 무슨 까닭이냐?” “내일 학교로 가보자!” 하고 어머니는 말끝을 흐리었다. “왜 학교를 안 다니우? 학교만 다니면 그만이지......” 어머니께서는 늘 이런 말을 하신다. “아니 학교도 그만둬야지.” 나는 이렇게 대답하였다. “글쎄, 학교를 그만두는 게 좋지 않겠니. 그까짓 학교란 게 무슨 의미가 있단 말이냐. 학교라는 게 어디 있어? 어디가 어디야.” 어머니가 이렇게 물으시자 나는 그제야 가슴이 덜컥 내려앉는 것 같았다. “선생님! 어머님께서는 어떻게 하실 작정이십니까?” 어머니의 물음에 나는 아무 대답도 없이 대답만 하였다. “어머님\n",
      "   3  어둠 속에서 어둠 속에서도 자태는 또렷하였다. 충동적으로 몸은 쏠리었다. 그 순간 눈을 굴린 것은 나만이 아닐 것이다. 어둠 속에 자태를 감추고 눈을 감고 있는 것은 내 자신뿐이 아니었다. 나는 눈을 떴다. 눈을 뜨는 순간에 나는 그 자리에 섰다. 어둠 속에서도 나는 또 한 번 눈을 번쩍 들었다. 그것은 나의 본능적 본능이었다. 나는 본능적으로 눈을 돌렸다. 그러나 그것은 내 본능에 대한 본능적인 본능이요 본능의 본능인 것이다. 그 본능은 내 자신의 본능을 억제하는 본능이다. 나는 이 본능과 본능과의 괴리 속에서 몸을 움직였다. 그러나 나는 그것을 억제할 수 없었다. 그것은 나 자신만이 아 니었다. 본능도 아니요, 본능 도 아니었던 것이다. 그러나 본능조차도 나를 억제하지 못하였다. 나는 무의식적으로 몸을 홱 돌리려 하였다. 그러나 이 순간의 나의 의식은 나만의 것이 아니 었다. 내 의식의 중심은 어둠에 있었다. 어둠 속의 나의 자 태는 또한 나의 그것과 흡사하였다. 그러나 그 때 나의 마음은 다시금 충동에 쏠렸다. 나는 다시 눈을 떠서 어둠 속으로 눈을 던졌다. 그러나 눈을 다시 굴리는 것은 그뿐만이 아니었 다. 어둠은 나의 마음을 움직인다. 내 마음속에는 어둠이 있었다. 내 마음은 어둠을 향하여 움직\n",
      "   4  흥식이는 옥지의 말을 너무도 신용하는 우식이가 미워서 혼사 준비에 대하여는 아무 말도 하지 않았다. “혼사 준비를 어떻게 하실 작정이오?” “무슨 말씀입니까?” “그것은 옥지씨의 말이지요.” 옥지는 아무 대답도 없었다. “그러면 어떻게 할 작정입니까.” “어떻게 하면 좋을까요?” “아무 말씀도 안 드리겠어요.” 흥식이의 말에는 옥지가 미웠다. “그럼 어떻게 해야 좋을까?” “우식이의 말을 믿어 주세요.” 하고 우식이에게 물었다. 그러나 우식은 대답이 없었다. “글쎄, 그까짓 말씀이 무슨 말씀이에요. 무슨 말씀을 하시는지 알 수가 없습니다.” 우식의 대답은 아무 것도 아니었다. “왜 그러십니까? 그 말씀은 옳지 않아요. 그 말씀을 믿지 않으시면 안됩니다.” 그러나 흥식은 옥지를 미워하는 것을 알 수 있었다. “그런 말씀 마세요. 그 말을 믿을 수가 없어요. 이 말씀만은 꼭 믿어야 할 것 같습 니다. 그 말만 믿으셔도 좋습니다. 그 말이 옳을지 모르지만 이 말씀을 믿을 수 없어요? 그 말은 옳은 말이에요. 그러나 이 말만은 믿읍시다. 이 말을 믿는다면 이\n",
      "   5  물에 빠진 시체의 손과 손이 서로 생선 엮듯이 매어 있는 것은 난파를 각오한 그들이 최후의 운명을 함께했다는 표시이다. 물에 빠져 죽은 시체들의 손은 서로 엉겨붙어 있고 그 손에는 생선이 엮듯 매어져 있는 것이다. 이것은 난파한 그들의 최후 운명이 서로 함께했음을 표시하는 것이다. 물에 빠졌거나 물에 떠내려갔거나 또는 물에 휩쓸려 죽었거나 하는 시체는 서로 손을 잡고 생선을 엮어 매고 있는 것이었다. 이 두 가지의 표정은 모두 난파의 각오와 그들이 함께한 것을 표시한 것이다. 이 세 가지 표정의 표정과 표정이 서로 다른 것은 이 시체가 물에 뛰어든 지 사흘이 못되어 죽게 되었다는 것을 나타낸 것이다. 시체를 물에 던져 죽이려 할 때에 그 시체에 손을 대어 놓았던 것이 바로 이 ‘생선’묶음이었다. 이 생선은 서로 얽어매인 것이요, 서로가 서로 묶여 있는 것 이 바로 생선의 엮음인 것이다.\n",
      "      이 생선과 손의 묶음이라는 것은 시체와 손 사이에 서로 연결되어 있다는 것을 의미한다. 이 생명의 묶음이야말로 생명이다. 생명과 생명의 묶음은 생명으로 말미암아 죽음에 이르렀을 때 그 생명은 죽음과 함께 하는 것이다.\n",
      "   6  LC당원의 경성 출현은 조선 여행일 수도 있고 또 조선 당국의 특수부호를 이용한 가두 연락이라거나 윤 백작 댁 습격 등을 보았을 때 단순 관광은 아닌 것이 분명하다. 그러나 그 경성의 출현이 단순한 여행이 아님을 알 수 있다. 그 러나 경성이 출현된 후의 경성은 조선에 있어서의 것이 아니라 조선으로의 여행인 것은 틀림없다. 조선에서 경성을 출현, 혹은 경성으로의 출현을 하였다는 것은 결코 단순 여행은 아 니었다. 그러나 경성에의 출현이라든가, 경성과의 접촉이라든지 혹은 윤백작의 습격이 있었다는 것 등을 볼 때 경성도 단순한 관광이아닌 것은 분명하 다. 그뿐이 아니다. 경성,의 출입은 조선여행의 일종으로 볼 수 있는 것이 다. 조선행 비행기 편을 이용하였다든지, 혹은 조선여행을 하였다든가 하는 것은 모두 조선의 여행에 의한 것이 아니며 조선 여행이 아니었던 것은 아니다. 다만 조선 여행을 하였을 뿐이 다. 그러나 이 여행의 목적에 있어서도 조선인의 특수한 부호를 이용하 였다거나 혹은 혹은 그 부호의 이용이라든가 또는 그 외의 여러 가지의 특이한 사 람들의 습격한 것 을 볼 때에 단순\n",
      "   7  수길이는 효성스러운 태도와 우수한 성적을 겸비하여 이웃 사람들과 담임 선생님의 사랑을 한 몸에 받았다. 그 러한 수길이의 성품은 그 어느 때보다도 효성이 지극하였다. 수 길이는 학창시절부터 학업에 열중하여 공부도 열심히 하였다. 학비도 넉넉히 벌고 학위도 잘 따고 공부에도 열심이었다. 학비가 넉넉한 편은 아니나 학비는 넉넉하게 벌었다. 학비를 벌기 위하여 학원을 다니면서 학업을 계속하는 동안에 수 길이도 학원에 다니게 되었다. 수 길은 학원으로 다니며 학비와 생활비를 마련하는 한편으로 학급의 학생들 틈에 끼여 공부하는 것을 도맡아 하였 다. 학기 초에 학원의 교장선생님이 수길을 찾아오셨을 때에도 수길은 그 교장으로부터 ‘선생님!’ 하고 부르짖으셨다. “선생님, 선생님!” “네?” “그렇습니다.” “어떻습니까.” “아니요.” “이것은 선생님 말씀이 아니외다. 선생님께서 말씀하신 바와 같이, 선생님은 저를 선생님으로 모시어 주셨습니다. 선생님께서는 제가 선생님을 모시고 다니시는 동안에도 저를 사랑하여 주시었습니다. 나는 선생님께 감사드리고\n",
      "   8  황진이는 지족선사의 제자가 되기를 청하였다. 그러나 선사는 냉정히 거절하였다. 황 진이는 과부 복장을 하고 청아한 목소리로 축원문을 읽었다. “황진아!” “지족선생님의 제자이신지?” “그렇습니다.” “아니오, 지 족선생님이시옵니다.” 황진이도 선사의 청을 거절하였으나 선사가 냉정하게 거절하는 것을 보고는 다시 과부의 복장으로 청해 왔다. “그러면 과부가 될 수 없겠읍니까?” “어떻든 과부는 될 수가 없읍니다. 그 대신 과부를 해 주십시오.” 이렇게 청하여 놓고는, “과부가 되려면 과부로 해 주시옵소서” 하고 축원을 하였다. “자네가 제자를 해 주신다면 과부에 해 드리지요.” 이 말을 듣고 황진은, “그럼 과부와 해주시옵소이다.” 라고 대답하였다. “네, 제자는 해드리지 못하겠읍니 다.” “이제부터라도 제자의 해는 해 드리도록 하겠읍니다마는......” 그 말을 듣자 황진의 가슴은 벅차올랐다. “어디로 가십니까. 어디선가 보신 적이 있읍니까?......그것은\n",
      "   9  영솔장의 지시에 따라 모인 사람들은 모두 총을 어깨에 둘러메고 무덤 일곱이 가지런히 놓인 곳으로 걸어갔다. 그 가운데서 가장 나이 많고 경험 많은 영 솔장이었다. 그도 역시 나이 많고, 경험 많았다. 그이들은 모두 자기네들끼리 모여서 그네들의 무덤을 둘러보았다. 이윽고 그 무덤의 일곱은 가지가지 흩어져서 흩어졌다. 그 중에도 가장 나이가 많고 경험이 많은 이들도 있었다. 모두들 그 네네의 무덤에 모여들었다. 이 일곱을 가리켜서 무덤이라고 하였다. 이 다섯은 모두 나이 많은 사람들이었다. 그리고 그 중에 한 사람씩은 나이 어린 사람이 있었다. 그리고 한 사람은 나이가 많은 사람이었다. 그리고 또 한 사람이 나이 든 사람이 있다. 그 사람은 나이 먹은 사람이다. 나이든 사람이면 누구나 다 나이와 경험이 많다. 그리고 나이가 많으면 많을수록 경험도 많아진다. 그러나 나이가 든 사람은 그 나이보다 훨씬 경험이 적다. 나이가 많아서 경험은 적지만 경험의 많고 적음은 그보다 더한 것이 없다. 나이 적은 사람은 경험에 비하여 경험이 적은 사람이다.\n",
      "      그는 나이가 들수록 경험이 많아지는 것을 알았다. 나이 많아도 경험에는 많은 것이 있는 것이다. 경험이란 경험이다. 경험이라는 것은 경험이라고 할 수 없다. 경험이라 함은 경험으로\n",
      "\n",
      " Korean BART Fine-tuning Output:\n",
      "\n",
      "  Id  Input Text                                                                                                                                                   Target Text\n",
      "----  -----------------------------------------------------------------------------------------------------------------------------------------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "   0  동경으로 떠나게 된 실은 눈을 붉히며 떠날 용기가 나지 않아서 떠나는 날짜를 흐려오던 것이다.                                                                   “이 걱정쟁이 같으니 누굴 칠면조나 카멜레온으로 아나부다.” “저 없는 동안에 모두들 충충대서 마음을 변하게 하문 어떻게 해요. 정말 걱정예요.─전 그렇게 되면 죽을걸요 뭘.” “어서 내 염려 말구 당신 마음의 고삐나 든든히 잡아 둬요. 행여나 대중없 이 노여나지 나 말게.” “인전 그만둬요 그런 소리. 듣기만 해두 소름이 끼쳐요.” 지난 두 달 동안의 변화와 수많은 굴곡을─행복과 불행의 가지가지를 반성하면서 벌써 그것이 과거가 되고 추억이 된 것이 신기해서 견딜 수 없었다. 뭇 인물들의 왕래와 미묘한 인심까지를 아울러 생각할 때 두 사람이 꾸며 떼어 그 조그만 한 폭의 역사가 또한 인간생활의 장한 한 페이지로 여겨졌다. 그 한 폭을 주초로 하고 앞날의 발전이 훤하게 내다보이는 것이 두 사람의 마음을 한량없이 밝게 해주었다. 스스로의 운명을 스스로들 개척해 가는 용기 앞에는 하나의 확고한 결정이 있을 뿐이었다. 미래에 속하되 미래가 아닌 결정이었다. 삼한이 풀리고 사온이 시작되는 날 드디어 실은 동경으로 길을 떠나게 되었다. 날마다 학교로 오는 전화가 그날은 특별히 아침 일찍이 왔다. “오늘 떠나게 될는지두 모르겠어요. 안녕히 계셔요.” 실은 역에서 보냄을 받기를 좋아하지 않는 성질에 떠나는 날짜의 결정을 언제나 확 적히 작정하지 않고 흐려오던 것이었다. 세상에 작별같이 마음 성가신 일이 없어서 역에서 마주 보고 눈들을 붉히면 도저히 떠날 용기가 생기지 않는다는 것이었다. 언제나 떠나게 되면 말없이 가만히 떠나겠다고 하던 것을 생각하고 그날 아침 전화로 준보는 혹시 이날이 아닌가 설레면서 물었다.\n",
      "   1  입내할 채비를 갖추고 기다리고 있던 대원군은 날이 어둔 후 창덕궁으로 들어갔다.                                                                                그에 대조되어, 세도하고 행학하던 사람들은 벼락을 맞은 듯 숨어 들어가 몸을 떨었고. 경풍하여 어찌할 바를 모르고처음부터 떨고만 있던 고종은, 급한 대로 하 릴없이 대원군의 입내를 명하였다. 이미 날이 어둔 후였다. 대원군은 마침 입내할 채비로 의관을 갖추고 교군까지 등대시키고서 기다 리고 있었다. 대원군은 즉시 창덕궁으로 들어갔다. 고종은 대원군에게 시국의 수습을 부탁하였다. 대원군은 스스로가 계획은 하지 아니한 쿠데타를 횡재한 것이었었다. 대원군은 의기양양 관물헌에 높이 앉아 우선 반란군에게 궁중으로부터 물러나갈 것을 명령하였다. 반란군은 대원군이 다시금 집정의 자리에 오른 것을 만세부르면서 순순히창덕궁으로부터 물러나갔다. 이때나 그 뒤에나 대원군은 반란과 범궐의 죄를 다스리기 위하여 형 식상으로나마 한 명의 범인도 체포한 것이 없었다. 대원군도 반란군도 민비는 정녕 난군의 손에 죽었거니 하였다. 과연 이튿 날 아침에도 민비는 궁중에서 보이지 아니하였다. 대원군은 안심하였고, 밝는 날 아침 부랴부랴, 국상을 발표하였다. 민비는 그러나 하마 위태할 뻔까지 하였던 것을 홍재희라는 군사 에게 업히어 궁녀인 것처럼 하고 몸을 화개동 윤태준의 집으로 피 하였다가, 이튿날 새벽 셋교군을 얻어 타고서, 그 생지인 여주 로 무사히 달아나가지고, 여주로는 안심이 아니 되어 다시 장호원 으로 옮아 민응식의 집에서 행색을 숨기고 환궁하던 팔월까지 머물 러 있었다.\n",
      "   2  어머니께 가면 항상 친절하게 잘해주셨지만 아파트의 사무원은 그만두라는 말을 항상 하셨고 오늘은 동경 같은 곳으로 학교를 다녀보는 게 어떻겠냐는 말까지 나왔다.  “면도를 빌려드릴까요?” 그러니까 사내는 머리를 극적극적 긁으며, “에이 뭐 면도는요.” 하고 데석을 설레설레 털었다. 그러나 잠시 더 멍청하니 서서 거울을 바라 보다가, “제 면도가 아마 여기 있을 거예요.” 그러니까 힐끗 무경이를 본다. 남의 남자에게 면도를 빌려준다는 것도 생 각해보면 수상쩍은 일이어서 나직이 변명하듯이 서랍에서 면도를 찾으며 중 얼거린다. “이사 올 때 잊었다가 핸드백에 넣었더니 배가 불러서 꺼내두었었는 데…… 여기 있습니다. 잘 들는지 모르지만 써보시지요. 전 통이 쓰지 않습 니다.” 그래서 이관형이는 면도를 얻어 들고 비누곽을 타월로 잘라 맨 것을 디룽 궁디룽궁 휘저으며, 욕탕 있는 데로 갔다. 그 뒷모양이 우스워서 무경이는 욕탕 안으로 사라질 때까지 그것을 창문 너머로 바라보고 있었다. 004시가 가까워서 사무실은 강영감에게 맡겨놓고 무경이는 다녀온 지도 얼 마 되고 하여 어머니한테로 갔다. 어머니와 정일수 씨는 장충단 이 편 앵구 장이라는 주택지에 살고 있었다. 가면 언제나 반가워하고 쓰다듬어 줄듯이 고맙게 친절히 해주었으나 한 시간 쯤 앉았노라면 으레히 인제 아파트의 사 무원은 그만두는 게 어떠냐는 권면이 퉁겨 나오곤 하였다. 먹을 것이 없니 입을 것이 없니 방 한 칸을 빌려 갖고 사는 건 살림이 간편해서 네 말 마따나 좋을는지 모른다 쳐도 무엇 때문에 남에게 구속받는 생활을 하면서 뭇사람의 시중을 드느냐 하는 것이 언제나 판에 박은 듯이 나오는 어머니의 말이었다. 어머니나 정일수 씨가 그렇게 생각하는 것도 무리는 아니었고 무 경이 자신조차도 그러한 생각을 먹어볼 때가 있으므로 그런 말이 나올 때마 다 그는 그저 좋은 말로 어루만져두는 것이었으나 오늘은 기어이 속 시원히 동경 같은 데루 학교나 가보는 것이 어떠냐는 말까지 나오고야 말았다.\n",
      "   3  어둠 속에서도 자태는 또렷했고 충동적으로 몸은 쏠리었는데 그 순간 눈을 굴린 것은 나만이 아닐 것이다.                                                          야릇한 방, 페페의 정성, 준비된 식탁, 갸비이의 호기심, 페페의 열정 ─ 두 사람의 사랑은 세상에서 제일가는 신기하고도 뜨거운 것이다. 갸비이의 두 눈은 별같이 탄다……. 그 불타는 화면에서 문득 내 시선을 떼게 한 것은 몇 자리 앞에 앉은 아키임과 마리이의 돌연한 거동이었다. 영화에서 감동을 받음인지 별안간 페페와 갸비이를 모방해서 그들의 열정을 연장시킨 것이다. 충동적으로 몸을 쏠리더니 번개같이 얼굴을 댄다. 어둠 속으로도 그 열광적인 자태는 또렷하게 눈에 띠었다. 그 순간 눈을 굴린 것은 나만이 아닐 듯싶다.\n",
      "                                                                                                                                                                   그들은 한참이나 있다가 얼굴을 뗐으나 몸은 그대로 가까웠다. 나는 영화에서는 벌써 마음이 떠서 두 사람만을 쏘아보게 되었다. 변괴는 뒤를 이어 일어났다. 두 사람의 거동을 보고서인지 옆에 앉았던 크리이긴은 벌써 자리에서 일어섰다. 무죽거리다가 아키임들을 향해 무어라고 지껄이더니 마리이의 손을 잡는 것이었다. 함께 밖으로 나가자는 눈치인 듯했다. 아키임이 대꾸하면서 엉거주춤 자리를 일어서서 실내기를 치다가 관객의 눈을 끌 것을 두려워함인지 주저앉으니까 크리이긴도 자리에 앉았다. 앉아서도 오고 가는 말이 한참이나 많은 모양이더니 이윽고 크리이긴은 혼자 자리를 일어서서 사잇길을 지나 비틀비틀 밖으로 나가 버렸다. 남은 아키임과 마리이는 아까와는 다른 조금 불안한 듯한 기색으로 정신없이 지껄거린다. 마음을 가라앉히기에는 오랜 시간이 걸리는 눈치였다. 크리이긴은 다시 안 들어오고 두 사람은 수군거리면서 벌써 영화는 보면 말면 하는 기색이었다.\n",
      "   4  흥식이는 옥지의 말을 너무도 신용하는 우식이가 미워서 혼사 준비에 대해 말을 하지 않았다.                                                                      과연 틀림이 없다. 백작의 집에서는 혼사 준비에 골몰하는 것을 볼진대 옥 지의 2 주일이란 말은, 한때의 속임수에 지나지 않는 것이 분명하다. 그러 나, 흥식이는 우식에게 이러한 말을 하지 않았다. 그 전 같으면 물론 통지해 주었을 터이지마는 너무도 우식이가 옥지를 신용함이 미워서 일부러 한 번 속이려고. 이와 같이 속아야 우식이도 정신을 차릴 것이다. 지금 흥식이 가 생각하기는 옥지든지 우식이든지 서로 지지 않을 줄 알았다. 옥지는 끝끝내 우식이를 생각지 않을 것이요, 그와 반대로 우식이는 제 몸 이 망하더라도 자기의 요구함을 실행하려고 한다. 이 까닭에 나중에는 우식이와 옥지 사이에 또는 석구와 옥지 사이에 무슨 변괴가 일어날지 모를 것이다. 우식이도 기왕 시작한 일인즉, 원수를 갚게 되면 원수를 갚겠다고 결심하였고 옥지도 역시 이왕 그릇된 일인즉 나중에 죄악이 탄로되면 제 몸을 죽이는 한이 있더라도 지금에 와서 우식의 요구는 승낙하지 않겠다고 결심하였다. 이같이 굳은 결심을 가진 옥지에게 우식이와 같은 큰 대적이 있으니 이번 결혼식을 과연 무사하게 치를지는 의문이지마는 한편으로 백작의 집에서는 혼사 준비를 모두 비밀에 붙였다. 구태여 비밀이랄 것은 없지마는 하여간 백작의 병세가 위독하여 온 집안이 근심 중에 있으므로 굉장히 떠들지는 못하게 되었다. 물론 평시 같으면 온 세상이 다 알도록 떠들었을 것이다. 혼인도 중하지마 는 첫째 옥지는 백작의 무남독녀로 상당한 지위와 재산이 있는 터인즉 남의 집 혼사보다는 몇백 몇천 배되게 하였을 것이다.\n",
      "   5  물에 빠진 시체의 손과 손이 서로 생선 엮듯이 매어 있는 것은 난파를 각오한 그들이 최후의 운명을 함께했다는 표시이다.                                           얼마 뒤에 그 시체는 바닷가 모래 언덕 위로 옮기었다.\n",
      "                                                                                                                                                                   그러나 물에 빠진 시체인 그 사람들이 생명이 붙어 있어서 노도광풍과 싸울 때에 무엇을 생각함이든지, 그 시체들은 서로 손과 손을 생선 엮듯이 단단히 매었다.\n",
      "                                                                                                                                                                   이 손과 손을 서로 묶은 것은 마을 여러 사람들에게는 해석하기 어려운 한 수수께끼였었다. 물론 시체를 수용하러 나간 마을 사람들이 묶은 것은 아니 었다. 그들은 물에서 건진 그대로 배에 싣고 돌아온 것이었다. 그들이 난파 를 각오하고 생명이 떠난 시체로 마을에 돌아갈 것으로 스스로 절망할 때, 뒷날 시체 찾는 사람들의 수고를 덜기 위하여 또는 한 배에서 최후의 운명 을 같이하였다는 것을 표하기 위하여 손과 손을 단단히 맨 것이었다.\n",
      "                                                                                                                                                                   이것이 생선 엮음처럼 늘어떼어 시체를 위하여 대변하는 말이었다.\n",
      "                                                                                                                                                                   이 시체들은 집으로 돌아갈 권리조차 생명이 떠나는 동시에 잃어버리었다.\n",
      "                                                                                                                                                                   그 바닷가에서 밤을 지내게 되었다. 이것은 남아 있는 가족의 행복을 위함 이었다. 다시 그러한 저주에 걸리지 않기를 바람이었다.\n",
      "                                                                                                                                                                   해는 다시 졌다. 시체가 놓인 바닷가에서 거화는 바다 물결에 길게 비치었다. 물결이 움직일 때마다 불빛이 바다 위에 뛰놀았다. 울음소리만이 가끔가끔 들리었다.\n",
      "                                                                                                                                                                   오륙 개 시체가 마을에 돌아온 뒤로는 나머지 다른 사람의 소식은 영영 알 수 없었다. T어촌 앞바다에 배가 떠 올 때마다 소식을 모르는 가족을 가진 사람들은 가슴을 따며 갯가로 덤비었으나, 그것은 매양 알 수 없는 장삿배 나 그 마을 다른 사람들의 돌아오는 배였다.\n",
      "   6  LC당원의 경성 출현은 조선 여행일 수도 있으나 LC당원의 특수부호를 이용한 가두 연락이라거나 윤 백작 댁 습격 등을 보았을 때 단순 관광은 아닌 것이 분명했다.     ‘LC당의 경성 본거는 어디냐?’ 필호와 작별을 하고 자기의 아파트로 돌아오면서 인준이는 연하여 머리를 기울였다.\n",
      "                                                                                                                                                                   LC당의 관계좌라 한들 조선땅 안에 여행을 오지 말라는 법은 없다. 그러나 이번 LC당원의 경성 출현은 단순한 여행으로는 볼 수가 없었다. 그들 특수 의 부호를 이용해 가면서 하는 가두 연락이라든가 윤 백작 댁 습격이라든가 이런 점으로 보아서 단순한 만유는 아닌 것이 분명하였다. 그리고 LC당으로 사건을 전개시키려고 잠입하였다 하면 한두 명의 당원만 잠입하였을 것이 아니라 적어도 십여 명의 당원이 가지각색의 계급의 인물로 가장을 하고 잠 입하였을 것이다.\n",
      "                                                                                                                                                                   여기서 인준이는 자기의 임무에 방해되는 커다란 방해물을 직각하였다. 경 찰이 의심도 할 겨를이 없이 전광석화와 같이 자기의 임무를 다 하고 상해로 도로 탈주를 하여버리려고 몸소 자기가 조선 안에까지 들어왔던 이번의 임 무가 뜻하지 않은 방해자 때문에 착오가 생기려는 데 대해서 인준이는 속으 로 혀를 채었다.\n",
      "                                                                                                                                                                   LC당의 목적이 무엇인지는 인준이에게는 너무도 명료하였다. 조선 경찰에 서는 이래 두고두고 연구를 하고 조사를 한 뒤에야 비로서 LC당의 목적이 무엇인지를 알 것이지만 인준이에게는 너무도 명료하였다.\n",
      "                                                                                                                                                                   ─ 같은 토끼를 따르는 두 마리의 개 ─.\n",
      "                                                                                                                                                                   인준이 자기의 목적물과 LC당의 목적물과는 동일한 것이라는 것은 과히 틀 림이 없는 추측일 것이다.\n",
      "                                                                                                                                                                   이같은 목적물을 향하여 세계적 범죄 단체인 LC당과 자기와가 여기서 대립하게 되는 모양이었다.\n",
      "   7  수길이는 효성스러운 태도와 우수한 성적을 겸비하여 이웃 사람들과 담임 선생님의 사랑을 한 몸에 받았다.                                                         희망의 꽃 연성흠 수길이 아버지는 소반을 만들어 파는 것으로 생계를 삼으시는 가난한 사람 이었습니다. 그의 집은 서울에서도 가난한 사람이 많이 모여 사는 동촌 어느 구석 어느 집 줄 행랑채였습니다. 사방 한 칸밖에 되지 안는 공장과 이 공장 과 맞붙어 있는 한 칸 방이 수길이 집 다섯 식구의 침실이요, 식당이었습니 다. 또 어느 때는 이 방이 사랑으로도 쓰여질 때가 있었습니다. 이같이 좁다란 공장 속에서 그 아버지는아침부터 밤까지 죽을 애를 써가 며 일을 하시는 것만도 거기서 생기는 것을 가지고는 다섯 식구가 굶지 안 고 먹어가기조차 퍽 어려운 형편이었습니다. 그래서 수길이가 학교에서 돌아 오기만 하면 붙잡아 앉아 놓고 일을 조금이라도 더하실 생각에 시중을 들 도록 하십니다. 시중을 시키시기만 할 뿐 아니라 잔심부름을 모조리 시키셨 습니다. 동무 애들은 연을 날린다, 팽이를 돌린다, 공을 찬다, 하건만 수길이는 대패 질도 하고 못도 박고 심부름도 하여 조금도 쉴 틈이 없었습니다. 그러나 마 음이 착하고 부모님께 퍽 효성스런 수길이는 아버지나 어머니의 말씀을 한 번도 거스르지 아니하고 부지런히 일을 하였습니다. 아버지 하시는 일을 도 와드릴 게 없으면 어린 동생을 보아주어 어머니의 일을 덜어드렸습니다. 이웃 사람들은 수길이의 이 효성스런 태도를 보고는 모두들 감동하여 누구 하나 칭찬 안하는 이가 없었습니다. 그리고 학교의 공부 성적도 번번이 우 등이므로 담임 선생님까지 장래에 유망한 소년이라고 칭찬하시며 퍽 사랑하 였습니다.\n",
      "   8  황진이는 지족선사의 제자가 되길 청했으나 선사가 냉정히 거절하자 이후 과부 복장을 하고 청아한 목소리로 축원문을 읽었다.                                       황진이는 이와 같이 서화담을 한 번 시험하여 본 뒤에 다시 지족선사를 시험하여 보려고 지족암을 찾아가서 자기가 제자가 되어 수도하기 를 청하니 지족선사는 여자는 원래 가까이할 필요가 없다고 하며처음부터 절대 거절을 하였었다. 황진이는 그 선사의 태도가 너무도 냉정하여 말도 부치기가 어려움을 보고 혼자 말로 \"오냐 어디 보자 진 소위 새침더기 골로 빠진다고, 네가 아무리 도도한 척 을 하여도 나의 묘계에 한 번 빠져보리라……\" 하고 돌아와서 며칠 있다가 다시 소복 단장으로 청춘 과부의 복색을 하고 지족암으로 가서 그 선사가 있는 바로 옆방에다 침소를 정하고 자기의 죽은 남편을 위하여 백일간 불공을 한다고 가칭하고 밤마다 불전에 가서 불공을 하는데 자기의 손으로 축원문을 지어서 청아한 그좋은 목청으로 처 량하게 읽으니 그야말로 천사의 노래도 같고 선녀의 음률도 같어서 아무 감 각이 없는 석불금불이라도 놀랄 만하거던 하물며 감각성이 있는 사람으로서 그 누가 감히 귀를 기우리고 듣지 않을가 보냐. 이와같이 며칠 동안을 계속 하여 불공축원을 하니 노선사가 처음에는 무심하게 들었으나 하루 이틀 들 을수록 자연히 마음에 감동이 생겨서 그 三十[삼십]년 동안이나 잔뜩 감고 옆에 사람도 잘 보지않던 눈을 번쩍 떠서 황진이의 태도를 한 번 보고 두 번 보니 보면 볼수록 선계의 정념은 점점 없어지고 사바 의 욕화가 일어나기 시작하여 불과 며칠에 황진이와 서로 말을 부치게 되니 진이는 예의 그 능란한 교제술과 영롱한 수완으로 그 선사를 마음으로 놀리 어서 최후에는 그만 파계를 하게까지 되니 지금까지 세상에서 쓰는 망석중 놀리듯 한다는 말이라든지 십년 공부 아미타불이라는 말은 그 사실을 일러서 하는 말이요, 속간에서 흥행하는 망석중노름이라 하는 것 도 또한 그 사실을 실연하는 것이다.\n",
      "   9  나이 많고 경험 많은 영솔장의 지시에 따라 모인 모두는 총을 어깨에 둘러메고 무덤 일곱이 가지런히 놓인 곳으로 걸어갔다.                                         “자 ──어서 모이오!” 하고 영솔장은 소리를 쳤다. 여기는 대장이니 하사니 없었다. 영솔장이라고 모든 사람을 영솔하는 이인데 이 모든 사람 가운데서 가장 나이 많고 경험 많은 이가 뽑혀서 된 것이다. 그렇게 이름이 영솔장 뿐이오 서로 부를 때에 는 동리에서 부르던 때와 같이 형님 아즈버니 하고 있다. “다 모였소” “네, 다 모였소!” “그러면 떠납시다. 그런데 가는 길에 두고 가는 형제의 무덤을 찾아보고 갑시다.” 영솔장의 말이 떨어지자 모두 총을 어깨에 둘러메고 걸음을 걸었다. 쌀쌀한 달 아래 소리 없이 열을 지어 나아가는 그 그림자는 바야흐로 떠오 르는 태양이나 맞으러 가는 듯이 씩씩하고도 알 수 없는 근심에 주저거리는 것 같았다. 거칠은 서리 숲을 지나서 그늘진 산비탈로 올라간 사람들은 한 곳에 이르 러서 모여 섰다. 거기는 무덤 일곱이 가지런히 놓였다. 모든 사람들의 수수 거리던 소리는 물 뿌린 듯이 고요하였다. 모두 육십 오 명이 떠나서 오십 칠 명이 돌아가게 되었다. 나머지 팔 명은 적탄에 죽었다. 그 중 한 명의 시체는 찾지 못하였다. 일곱 명만 찾아서 이 곳에 묻은 것이다. “여러 아우님!” 하고 영솔장은 무덤을 향하였다. “우리는 가오! 우리는 살아 가오!” 하고는 목이 메서 다시 무슨 소리를 못한다. 모든 사람들은 “자네를 두고…….” 하면서 목메인 소리를 쳤다. 이 가운데 끼인 창화는 종범의 무덤 앞에 가서 섰다. “종범아! 죽어도 같이 죽고 살아도 같이 살겠더니 너는 죽었는데 나는 살 았구나!” 말을 마치지 못하여 그는 눈물을 씻었다.\n",
      "\n",
      "Source documents:\n",
      "\n",
      "  Id  Document\n",
      "----  -----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "   0  동경으로 떠나게 된 실은 눈을 붉히며 떠날 용기가 나지 않아서 떠나는 날짜를 흐려오던 것이다.\n",
      "   1  입내할 채비를 갖추고 기다리고 있던 대원군은 날이 어둔 후 창덕궁으로 들어갔다.\n",
      "   2  어머니께 가면 항상 친절하게 잘해주셨지만 아파트의 사무원은 그만두라는 말을 항상 하셨고 오늘은 동경 같은 곳으로 학교를 다녀보는 게 어떻겠냐는 말까지 나왔다.\n",
      "   3  어둠 속에서도 자태는 또렷했고 충동적으로 몸은 쏠리었는데 그 순간 눈을 굴린 것은 나만이 아닐 것이다.\n",
      "   4  흥식이는 옥지의 말을 너무도 신용하는 우식이가 미워서 혼사 준비에 대해 말을 하지 않았다.\n",
      "   5  물에 빠진 시체의 손과 손이 서로 생선 엮듯이 매어 있는 것은 난파를 각오한 그들이 최후의 운명을 함께했다는 표시이다.\n",
      "   6  LC당원의 경성 출현은 조선 여행일 수도 있으나 LC당원의 특수부호를 이용한 가두 연락이라거나 윤 백작 댁 습격 등을 보았을 때 단순 관광은 아닌 것이 분명했다.\n",
      "   7  수길이는 효성스러운 태도와 우수한 성적을 겸비하여 이웃 사람들과 담임 선생님의 사랑을 한 몸에 받았다.\n",
      "   8  황진이는 지족선사의 제자가 되길 청했으나 선사가 냉정히 거절하자 이후 과부 복장을 하고 청아한 목소리로 축원문을 읽었다.\n",
      "   9  나이 많고 경험 많은 영솔장의 지시에 따라 모인 모두는 총을 어깨에 둘러메고 무덤 일곱이 가지런히 놓인 곳으로 걸어갔다.\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "print(\n",
    "    tabulate(\n",
    "        zip(\n",
    "            range(len(summaries_after_tuning)),\n",
    "            summaries_after_tuning,           \n",
    "#            summaries_before_tuning,\n",
    "        ),\n",
    "#        headers=[\"Id\", \"Output (Fine-tuned)\", \"Output (Zero-tuning)\"],\n",
    "        headers=[\"Id\", \"Output (Fine-tuned)\"],\n",
    "    )\n",
    ")\n",
    "print(\"\\n Korean BART Fine-tuning Output:\\n\")\n",
    "\n",
    "print(\n",
    "    tabulate(\n",
    "        zip(\n",
    "            range(len(summaries_after_tuning)),\n",
    "            list(test_samples[\"input_texts\"]),            \n",
    "            list(test_samples[\"target_texts\"]), \n",
    "        ),\n",
    "    headers=[\"Id\", \"Input Text\",\"Target Text\"]\n",
    "    \n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nSource documents:\\n\")\n",
    "print(tabulate(list(enumerate(test_samples[\"input_texts\"])), headers=[\"Id\", \"Document\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "654325c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'영솔장의 지시에 따라 모인 사람들은 모두 총을 어깨에 둘러메고 무덤 일곱이 가지런히 놓인 곳으로 걸어갔다. 그 가운데서 가장 나이 많고 경험 많은 영 솔장이었다. 그도 역시 나이 많고, 경험 많았다. 그이들은 모두 자기네들끼리 모여서 그네들의 무덤을 둘러보았다. 이윽고 그 무덤의 일곱은 가지가지 흩어져서 흩어졌다. 그 중에도 가장 나이가 많고 경험이 많은 이들도 있었다. 모두들 그 네네의 무덤에 모여들었다. 이 일곱을 가리켜서 무덤이라고 하였다. 이 다섯은 모두 나이 많은 사람들이었다. 그리고 그 중에 한 사람씩은 나이 어린 사람이 있었다. 그리고 한 사람은 나이가 많은 사람이었다. 그리고 또 한 사람이 나이 든 사람이 있다. 그 사람은 나이 먹은 사람이다. 나이든 사람이면 누구나 다 나이와 경험이 많다. 그리고 나이가 많으면 많을수록 경험도 많아진다. 그러나 나이가 든 사람은 그 나이보다 훨씬 경험이 적다. 나이가 많아서 경험은 적지만 경험의 많고 적음은 그보다 더한 것이 없다. 나이 적은 사람은 경험에 비하여 경험이 적은 사람이다.\\n그는 나이가 들수록 경험이 많아지는 것을 알았다. 나이 많아도 경험에는 많은 것이 있는 것이다. 경험이란 경험이다. 경험이라는 것은 경험이라고 할 수 없다. 경험이라 함은 경험으로'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_after_tuning[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2701a777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'어떤 남자가 남자가 빨간 오토바이를 타고 있는 것을 보았다. 어떤 남자는 빨간 자전거를 타고 있다. 어떤 여자는 빨간 고무보트를 타고 있고 어떤 사람은 빨간 자동차를 탄다. 어떤 남성은 빨간 바지를 입은 채, 어떤 여자와 나란히 서서, 어떤 여자의 뒤를 따라가며, 어떤 여자가 어떤 남자의 뒤를 따르고 있는 것이다. 어떤 남자와 어떤 여자를 사이에 두고 그 여자는 그 여자의 옆으로 가면서, “여보!” 하고 부르짖는다. “어디서 오셨어요?” “오라버니?” “아니오, 어디 갔다 왔어요.” “그러면 오시겠읍니까?” “이리 오십시오.” “어딜 가셔요.” 어떤 여편네는 이렇게 대답한다. “저기 오셔요! 어디 가세요? 어디 있셔요? 어디 있어요? 오시오. 어디 있지요?......” 그 여편의 대답은 의외로 간단하였다. “무슨 일인지 모르겠읍니다.” 이 여 편네의 대답이 의외의 대답을 하였다. “그런데 오시는 분은 어디 계십니까?.......” “한 번 가보세요.” 하는 여인의 대답이었다. “네, 가십시다.” 여자는 대답하였다. “그렇습니다.” 남편은 고개를 끄덕끄덕하며 “왜? ××가 오신단 말이오? 그까짓 게 오라 버렸단 말이지요. ─” 나는 대답하지 않았다. “그럼, 그놈이 오냐. 오냐, 그 놈이 왔다 갔어.” 여자의 대답에 남 편은 얼른 대답하였다.\\n“오냐, 이놈의 놈을 어떻게 해. 이 놈의놈을 죽여 버리겠소.” 그는 이렇게 말하였다. 그러나 그는 대답할 말이 없었다. “나도 오겠소이다.” 그의 대답에는 아무 대답도 없었다. 그는 다시 말을 계속하였다. “어떤 놈은 오느냐? 저놈은 왜 오냐?” 그러나 그 남자는 대답하는 대신에 그 여자를 쳐다보았다. “그것은 내가 오라고 한 것이 아니오. 나는 오라는 것이오. 오라, 오라. 오, 오! 오오! ── 오오.” 두 사람은 서로 마주 앉았다. 두 사람의 눈은 마주 마주 섰다. 두 사람 사이에는 무슨 말이 오고 가는 듯하였다. 그 사람의 얼굴에는 웃음이 흘렀다. 그러나 그의 눈에는 눈물이 맺혔다. 그 눈에서는 눈물이 글썽글썽하였다. 그는 또 한 번 울었다. 그는 울고 싶었다. 그의 울음소리는 점점 더 높아 갔다. 그의 가슴은 울렁거리기 시작하였다. 그의 입에서 나온 말소 리가 그의 귀에 들려왔다. ‘오냐!’ 하는 소리와 함께 그의 입술은 떨리기 시작했다. 그는 그 소리를 들었다. 그 목소리는 떨렸다. 그리고 그 소리는 다시 울렸다. 그는 그의 귀를 쫑긋하였다. 그리고 자기의 귀에서 흘러나온 말소리였다. 그는 자기의 귀를 기울였다. 그리고 자기 귀로 들렸다. 그 소리도 들리는 것 같았다. 그는 나의 귀에는 들리지 않았다. 그는 내 귀에도 들리었다. 나는 그 소리가 들린 것을 알았다. 나는 나의 귀를 의식하였다. 나는 내 귀를 의심하였다. 나의 눈에서 눈물이 핑 돌았다. 그러나 나는 그의 입을 열지 않았다. 나는 이 소리를 들을 수 없었다. 나는 울지 아니하였다. 내가 울음을 그치기를 기다리지 아니하였을 것이다. 나의 입에서는 울음이 새어 나왔다. 나의 가슴에서 울리는 소리였다. 나의 울음은 울려 나오는 것 같았었다. 나의 마음은 울음에 그칠 줄을 몰랐다. 나는 눈물이 그치고 말았다. 나의 눈물도 울었다.\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "        \"어떤 남자가 빨간 오토바이를 타고 있다.\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_target_length,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "input_ids = inputs.input_ids.to(model.device)\n",
    "attention_mask = inputs.attention_mask.to(model.device)\n",
    "\n",
    "outputs = model.generate(input_ids,\n",
    "                             max_length = 700,\n",
    "                             min_length=32,\n",
    "                             top_p = 0.92,\n",
    "                             num_beams=5,\n",
    "                             no_repeat_ngram_size=2,\n",
    "                             attention_mask=attention_mask)\n",
    "output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "output_str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66dd430a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'운동장에 모여 있는 사람들이 줄넘기를 하고 있다. 운동장에는 사람들이 모여 있다. 그 중에 한 사람씩은 줄을 긋고 있는 것이 보이고, 또 다른 한 사람은 줄을 그은 것이 보인다. 그 중에도 한 사람이 줄을 당기고 있는 것도 보이며, 또 한 사람의 다른 사람이 줄 넘기를 하는 것도 보 았 다. 그 중에는 한 사람도 줄을 이르고 있는 사람이 보이기도 하고, 또 어떤 이는 줄을 당기기도 하는 사람도 보이기는 보이는데 그 가운데에 한 사람, 또 그 옆에 서 있는 사람도 보이는 사람이 보이는 사람인 것 같다. 그리고 그 옆에는 다른 사람의 그림자가 보이는데, 그 그림자의 그림자는 그림자 그림자에 비추인 듯도 하다. 이 그림자를 보고 있는 사람은 누구인지 알 수 없으나 그림의 그림자도 보이지 않는다. 그림자와 그림자로 보이는 사람은 그림자인 줄만 알 뿐이다. 그림자들은 그림자에게 비치인 줄은 알 수가 없다. 그림자들이 그림자들의 그림자들을 보고 있노라니 그림에 비치는 그림은 그림이 아닌 줄도 모른다. 그림을 그리는 사람들은 그림 속에 비친 그림자나 그림같이 보이는 줄로만 보이는 줄을 안다.\\n그림자가 보이지 않 는 줄에는 그림도 비치지 않는 줄에 서는 그림들이 있다. 그림과 그림 사이에 있는 그림자들. 그림들은 그림으로 그려진 그림이다. 그림을 그리던 사람들은 줄에서 내려서 줄 위에 올라서서 그림이나 그릴 수 있는 줄의 그림을 그려 보았다. 그림 속에는 그림 한 장이 그려져 있다.\\n그림자를 그리지 않는 것은 그림뿐이 아니다. 그림에서 나오는 그림들도 그림일 것이다. 그림 속에서 그려지는 그림들. 그것은 그림인 줄을 모르는 줄 알면서도 그림이라고는 생각지 않는 그림이었다. 그림 속의 그림들을 그렸다 그렸다고도 생각되지 않는 것이 그림이었 다. 그림 가운데서 그림을 그리고 있는 사람이나 그림을 그린 사람이나, 그림 속 그림들과는 거리가 먼 줄 속에 있는 사람들, 그림속에 그려 있는 그림을 보는 사람 등등 은 그림속의 그림 같은 줄거리를 그렸던 것이 분명하다. 그림속 그림이란 그림과는 거리가 멀고 그림 그 자체도 그림 같기도 한 것이었다. 그림속에서 그려오는 그림이라면 그림보다 그림 이 더 아름답지 않은가? 그림보다도 그림이라는 것이 더 아름다울 수 있을 것 같지 않은 것일까.그림보다 그림을 더 아름답게 그려 놓았다면 그림 보다 더 아름다운 그림이었을까? 그 러나 그림보다는 그림 위에 그려 넣을 수 없는 그림이야기를 그려놓았으면 좋을 듯싶은 것일까? 그림만큼이나 그림같지도 않은 그림인가? 글쎄 그림만 그려 놓고 보면 그림 같지 않을까.\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "        \"운동장에 모여 있는 사람들이 줄넘기를 하고 있다.\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_target_length,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "input_ids = inputs.input_ids.to(model.device)\n",
    "attention_mask = inputs.attention_mask.to(model.device)\n",
    "\n",
    "outputs = model.generate(input_ids,\n",
    "                             max_length = 512,\n",
    "                             min_length=32,\n",
    "                             top_p = 0.92,\n",
    "                             num_beams=5,\n",
    "                             no_repeat_ngram_size=2,\n",
    "                             attention_mask=attention_mask)\n",
    "output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "output_str[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
